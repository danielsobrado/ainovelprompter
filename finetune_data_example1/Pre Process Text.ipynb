{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87198c65-4ea9-41d0-a85c-73fcbfae72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# General-purpose function to load JSON data\n",
    "def load_json(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found. Please ensure the file path is correct.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"File is not a valid JSON. Please check the file content.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Function to count entries in JSON\n",
    "def count_entries_in_json(data):\n",
    "    if data is not None:\n",
    "        return len(data)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9470228-270c-41a6-b01d-3a576e7c1542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "file_path = '/home/drusniel/llm_notebooks/analyzed_George_MacDonald.json'\n",
    "# Load JSON data\n",
    "data = load_json(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21018857-cbd0-42d6-924c-9c6f1345971e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in the JSON file: 182\n"
     ]
    }
   ],
   "source": [
    "# Count the number of entries in the JSON file\n",
    "number_of_entries = count_entries_in_json(data)\n",
    "print(f\"Number of entries in the JSON file: {number_of_entries}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9543563d-1872-4f03-b6c6-497d43162f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comma-separated tones: serene, charming, mysterious, intriguing, reflective, dreary, listless, suggestive, anticipative, curious, adventurous, tense, panicked, resolute, hopeful, concerned, evasive, imaginative, skeptical, insistent, dismissive, defensive, sarcastic, facetious, inquiring, assertive, challenging, indignant, accusatory, sorrowful, reproachful, adamant, disbelieving, frustrated, tender, conciliatory, forgiving, loving, affronted, offended, reassuring, irritated, apologetic, confident, endearing, thoughtful, calculative, friendly, accommodating, perplexed, unattended, unexpected, distressed, surprised, resolved, disappointed, gloomy, brightening, picturesque, disenchanted, reluctant, startled, anxious, realistic, unperturbed, frightened, terrified, alarmed, confused, exasperated, horrified, desperate, exhausted, dismayed, hopeless, disoriented, descriptive, inquisitive, pleading, cautious, reassured, playful, nervous, grateful, affectionate, action, relieved, conflicted, noble, contemplative, dramatic, ethical, consoling, focused, intrigued, animated, questioning, amused, conspiratorial, observant, strategic, sneaky, stealthy, commanding, humorous, anticipatory, awestruck, political, formal, joyful, excited, vivid, intimate, wistful, melancholic, painful, mystical, inviting, introspective, philosophical\n",
      "              Tone  Occurrences\n",
      "0           serene            1\n",
      "1         charming            1\n",
      "2       mysterious            4\n",
      "3       intriguing            1\n",
      "4       reflective            7\n",
      "..             ...          ...\n",
      "115        painful            1\n",
      "116       mystical            2\n",
      "117       inviting            1\n",
      "118  introspective            1\n",
      "119  philosophical            1\n",
      "\n",
      "[120 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to create a DataFrame from JSON data with tones and their occurrences\n",
    "# Prompt: map these tones in the 10 most significant tones for writting: Alarming, Light-hearted... give me the result in the following format:     tone_mapping = {\n",
    "#         \"Alarming\": \"Dramatic\", \"Gruff\": \"Dramatic\", \"Heated\": \"Dramatic\", \"Indignant\": \"Dramatic\",\n",
    "#         \"Suspenseful\": \"Dramatic\", \"Tense\": \"Dramatic\", \"Philosophical\": \"Thoughtful\", \"Pensive\": \"Thoughtful\",\n",
    "#         \"Reflective\": \"Thoughtful\", \"Inquisitive\": \"Thoughtful\", \"Curious\": \"Thoughtful\", \"Skeptical\": \"Thoughtful\",\n",
    "#         \"Light-hearted\": \"Positive\", \"Optimistic\": \"Positive\", \"Excited\": \"Positive\", \"Calm\": \"Calm\",\n",
    "#         \"Casual\": \"Calm\", \"Solemn\": \"Calm\", \"Determined\": \"Determined\", \"Resolute\": \"Determined\",\n",
    "#         \"Mysterious\": \"Mysterious\", \"Stealthy\": \"Mysterious\", \"Cautious\": \"Mysterious\"\n",
    "#     }\n",
    "\n",
    "def tone_occurrences_dataframe(data):\n",
    "    if data is None:\n",
    "        return pd.DataFrame(columns=['Tone', 'Occurrences'])\n",
    "    \n",
    "    tone_counts = {}\n",
    "    for entry in data:\n",
    "        tone = entry.get('tone', None)\n",
    "        if tone:\n",
    "            tone_counts[tone] = tone_counts.get(tone, 0) + 1\n",
    "\n",
    "    # Creating DataFrame from dictionary\n",
    "    tones_df = pd.DataFrame(list(tone_counts.items()), columns=['Tone', 'Occurrences'])\n",
    "    \n",
    "    # Print tones in a comma-separated format\n",
    "    comma_separated_tones = \", \".join(tone_counts.keys())\n",
    "    print(\"Comma-separated tones:\", comma_separated_tones)\n",
    "    \n",
    "    return tones_df\n",
    "\n",
    "# Generate the DataFrame\n",
    "df_tones = tone_occurrences_dataframe(data)\n",
    "print(df_tones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27fe63ff-444a-488e-a5b0-cca821f89de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been rewritten successfully.\n"
     ]
    }
   ],
   "source": [
    "# Function to rewrite JSON data with grouped tones and add an incremental ID\n",
    "def rewrite_json_with_grouped_tones(data, output_file_path):\n",
    "    tone_mapping = {\n",
    "    \"Serene\": \"Calm\", \"Charming\": \"Positive\", \"Mysterious\": \"Mysterious\", \n",
    "    \"Intriguing\": \"Thoughtful\", \"Reflective\": \"Thoughtful\", \"Dreary\": \"Gloomy\", \n",
    "    \"Listless\": \"Gloomy\", \"Suggestive\": \"Thoughtful\", \"Anticipative\": \"Positive\", \n",
    "    \"Curious\": \"Thoughtful\", \"Adventurous\": \"Excited\", \"Tense\": \"Dramatic\", \n",
    "    \"Panicked\": \"Dramatic\", \"Resolute\": \"Determined\", \"Hopeful\": \"Positive\", \n",
    "    \"Concerned\": \"Thoughtful\", \"Evasive\": \"Defensive\", \"Imaginative\": \"Creative\", \n",
    "    \"Skeptical\": \"Thoughtful\", \"Insistent\": \"Assertive\", \"Dismissive\": \"Defensive\", \n",
    "    \"Defensive\": \"Defensive\", \"Sarcastic\": \"Humorous\", \"Facetious\": \"Humorous\", \n",
    "    \"Inquiring\": \"Thoughtful\", \"Assertive\": \"Assertive\", \"Challenging\": \"Dramatic\", \n",
    "    \"Indignant\": \"Dramatic\", \"Accusatory\": \"Dramatic\", \"Sorrowful\": \"Gloomy\", \n",
    "    \"Reproachful\": \"Gloomy\", \"Adamant\": \"Determined\", \"Disbelieving\": \"Skeptical\", \n",
    "    \"Frustrated\": \"Dramatic\", \"Tender\": \"Affectionate\", \"Conciliatory\": \"Calm\", \n",
    "    \"Forgiving\": \"Calm\", \"Loving\": \"Affectionate\", \"Affronted\": \"Defensive\", \n",
    "    \"Offended\": \"Defensive\", \"Reassuring\": \"Calm\", \"Irritated\": \"Dramatic\", \n",
    "    \"Apologetic\": \"Calm\", \"Confident\": \"Assertive\", \"Endearing\": \"Affectionate\", \n",
    "    \"Thoughtful\": \"Thoughtful\", \"Calculative\": \"Strategic\", \"Friendly\": \"Positive\", \n",
    "    \"Accommodating\": \"Calm\", \"Perplexed\": \"Confused\", \"Unattended\": \"Negative\", \n",
    "    \"Unexpected\": \"Surprised\", \"Distressed\": \"Dramatic\", \"Surprised\": \"Surprised\", \n",
    "    \"Resolved\": \"Determined\", \"Disappointed\": \"Gloomy\", \"Gloomy\": \"Gloomy\", \n",
    "    \"Brightening\": \"Positive\", \"Picturesque\": \"Creative\", \"Disenchanted\": \"Gloomy\", \n",
    "    \"Reluctant\": \"Defensive\", \"Startled\": \"Surprised\", \"Anxious\": \"Nervous\", \n",
    "    \"Realistic\": \"Thoughtful\", \"Unperturbed\": \"Calm\", \"Frightened\": \"Dramatic\", \n",
    "    \"Terrified\": \"Dramatic\", \"Alarmed\": \"Dramatic\", \"Confused\": \"Confused\", \n",
    "    \"Exasperated\": \"Dramatic\", \"Horrified\": \"Dramatic\", \"Desperate\": \"Dramatic\", \n",
    "    \"Exhausted\": \"Gloomy\", \"Dismayed\": \"Gloomy\", \"Hopeless\": \"Gloomy\", \n",
    "    \"Disoriented\": \"Confused\", \"Descriptive\": \"Creative\", \"Inquisitive\": \"Thoughtful\", \n",
    "    \"Pleading\": \"Dramatic\", \"Cautious\": \"Defensive\", \"Reassured\": \"Calm\", \n",
    "    \"Playful\": \"Humorous\", \"Nervous\": \"Nervous\", \"Grateful\": \"Positive\", \n",
    "    \"Affectionate\": \"Affectionate\", \"Action\": \"Excited\", \"Relieved\": \"Positive\", \n",
    "    \"Conflicted\": \"Dramatic\", \"Noble\": \"Positive\", \"Contemplative\": \"Thoughtful\", \n",
    "    \"Dramatic\": \"Dramatic\", \"Ethical\": \"Thoughtful\", \"Consoling\": \"Calm\", \n",
    "    \"Focused\": \"Determined\", \"Intrigued\": \"Thoughtful\", \"Animated\": \"Excited\", \n",
    "    \"Questioning\": \"Thoughtful\", \"Amused\": \"Humorous\", \"Conspiratorial\": \"Mysterious\", \n",
    "    \"Observant\": \"Thoughtful\", \"Strategic\": \"Strategic\", \"Sneaky\": \"Mysterious\", \n",
    "    \"Stealthy\": \"Mysterious\", \"Commanding\": \"Assertive\", \"Humorous\": \"Humorous\", \n",
    "    \"Anticipatory\": \"Positive\", \"Awestruck\": \"Excited\", \"Political\": \"Dramatic\", \n",
    "    \"Formal\": \"Formal\", \"Joyful\": \"Positive\", \"Excited\": \"Excited\", \"Vivid\": \"Creative\", \n",
    "    \"Intimate\": \"Affectionate\", \"Wistful\": \"Gloomy\", \"Melancholic\": \"Gloomy\", \n",
    "    \"Painful\": \"Gloomy\", \"Mystical\": \"Mysterious\", \"Inviting\": \"Positive\", \n",
    "    \"Introspective\": \"Thoughtful\", \"Philosophical\": \"Thoughtful\"\n",
    "}\n",
    "\n",
    "    \n",
    "    for index, entry in enumerate(data, start=1):\n",
    "        original_tone = entry.get('tone')\n",
    "        entry['tone'] = tone_mapping.get(original_tone, original_tone) \n",
    "        entry['id'] = index  \n",
    "\n",
    "    try:\n",
    "        with open(output_file_path, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "        return \"JSON data has been rewritten successfully.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "# File paths\n",
    "file_path = '/home/drusniel/llm_notebooks/analyzed_George_MacDonald.json'\n",
    "output_file_path = '/home/drusniel/llm_notebooks/modified_data_George_MacDonald.json'\n",
    "\n",
    "# Rewrite the JSON file with added IDs\n",
    "result = rewrite_json_with_grouped_tones(data, output_file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62fde8d5-00ee-4016-a9c6-f61e4f9f1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompts_for_rewriting(input_file_path, output_file_path):\n",
    "    try:\n",
    "        with open(input_file_path, 'r') as json_file, open(output_file_path, 'w') as text_file:\n",
    "            data = json.load(json_file)\n",
    "            for index, entry in enumerate(data, start=1):\n",
    "                if 'text' in entry:\n",
    "                    text = entry['text']  \n",
    "                    prompt = (f\"Rewrite the following text in JSON format with your own words, \"\n",
    "                              f\"that is clearly recognized as GPT4 generated text by the descriptive wording and tone \"\n",
    "                              f\"and return the result in a JSON format with a field called 'id' that has number {index} \"\n",
    "                              f\"and a field called 'gptText' that has the text you rewrote, the text is:\\n{text}\\n\\n\")\n",
    "                    text_file.write(prompt)  \n",
    "                else:\n",
    "                    text_file.write(f\"No text found for entry {index}.\\n\\n\") \n",
    "        return \"Prompts have been written successfully to the text file.\"\n",
    "    except FileNotFoundError:\n",
    "        return \"The file was not found.\"\n",
    "    except json.JSONDecodeError:\n",
    "        return \"The file is not a valid JSON file.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaba2635-c223-4033-81eb-8ef1c3e7c8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts have been written successfully to the text file.\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "file_path = '/home/drusniel/llm_notebooks/analyzed_George_MacDonald.json'\n",
    "output_file_path = '/home/drusniel/llm_notebooks/instructions_George_MacDonald.txt'\n",
    "\n",
    "# Generate prompts for rewriting the text\n",
    "result = generate_prompts_for_rewriting(file_path, output_file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a06aa40-faaa-4b95-bb1d-e077b31ba6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data generated successfully. Output file: /home/drusniel/llm_notebooks/train_data_George_MacDonald.jsonl\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def escape_special_chars(text):\n",
    "    # Escape backslashes\n",
    "    text = text.replace('\\\\', '\\\\\\\\')\n",
    "    # Replace Unicode characters with their escaped representation\n",
    "    text = text.replace('\\\\u201c', '\\\\\"')\n",
    "    text = text.replace('\\\\u201d', '\\\\\"')\n",
    "    text = text.replace('\\\\u2019', \"'\")\n",
    "    text = text.replace('\\\\u2014', \"-\")\n",
    "    return text\n",
    "\n",
    "def generate_train_data(gpt_file, modified_file, output_file):\n",
    "    # Read gptStyle.json\n",
    "    with open(gpt_file, 'r') as file:\n",
    "        gpt_data = json.load(file)\n",
    "\n",
    "    # Read modified_data.json\n",
    "    with open(modified_file, 'r') as file:\n",
    "        modified_data = json.load(file)\n",
    "\n",
    "    # Create a dictionary to store the modified data entries by their IDs\n",
    "    modified_dict = {entry['id']: entry for entry in modified_data}\n",
    "\n",
    "    # Open the output JSONL file\n",
    "    with open(output_file, 'w') as output:\n",
    "        for gpt_entry in gpt_data:\n",
    "            gpt_id = gpt_entry['id']\n",
    "            gpt_text = gpt_entry['gptText']\n",
    "\n",
    "            if gpt_id in modified_dict:\n",
    "                modified_entry = modified_dict[gpt_id]\n",
    "                author = modified_entry['author']\n",
    "                tone = modified_entry['tone']\n",
    "                text_type = modified_entry['type']\n",
    "                modified_text = modified_entry['text']\n",
    "\n",
    "                # Escape special characters and Unicode\n",
    "                gpt_text = escape_special_chars(gpt_text)\n",
    "                modified_text = escape_special_chars(modified_text)\n",
    "\n",
    "                # Create the formatted text for the output JSONL file\n",
    "                formatted_text = f\"<human>:Rephrase the following text with in the style of {author}: {gpt_text}\\\\n<bot>: {modified_text}\"\n",
    "\n",
    "                # Create the metadata dictionary\n",
    "                metadata = {\"source\": \"gutenberg\"}\n",
    "\n",
    "                # Create the final dictionary for the JSON entry\n",
    "                jsonl_entry = {\"text\": formatted_text, \"metadata\": metadata}\n",
    "\n",
    "                # Write the JSONL entry to the output file\n",
    "                output.write(json.dumps(jsonl_entry) + '\\n')\n",
    "\n",
    "    print(f\"Train data generated successfully. Output file: {output_file}\")\n",
    "    \n",
    "gpt_file = '/home/drusniel/llm_notebooks/gptStyle_George_MacDonald.json'\n",
    "modified_file = '/home/drusniel/llm_notebooks/modified_data_George_MacDonald.json'\n",
    "output_file = '/home/drusniel/llm_notebooks/train_data_George_MacDonald.jsonl'\n",
    "\n",
    "generate_train_data(gpt_file, modified_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fa0d65a-ce7c-465f-9339-d8cbf72bd3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed. Output file: /home/drusniel/llm_notebooks/train_data_llama_factory_George_MacDonald.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def convert_jsonl_to_json(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        jsonl_data = file.readlines()\n",
    "\n",
    "    json_data = []\n",
    "\n",
    "    for line in jsonl_data:\n",
    "        data = json.loads(line)\n",
    "        text = data['text']\n",
    "\n",
    "        # Split the text into instruction, input, and output\n",
    "        parts = text.split('<bot>:')\n",
    "        instruction = parts[0].strip().replace('<human>:', '').strip()\n",
    "        output = parts[1].strip() if len(parts) > 1 else ''\n",
    "\n",
    "        # Create a new dictionary with the desired format\n",
    "        json_entry = {\n",
    "            'instruction': instruction,\n",
    "            'input': '',\n",
    "            'output': output\n",
    "        }\n",
    "\n",
    "        json_data.append(json_entry)\n",
    "\n",
    "    # Write the JSON data to the output file\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(json_data, file, indent=2)\n",
    "\n",
    "    print(f\"Conversion completed. Output file: {output_file}\")\n",
    "\n",
    "# Specify the paths for the input and output files\n",
    "input_file = '/home/drusniel/llm_notebooks/train_data_George_MacDonald.jsonl'\n",
    "output_file = '/home/drusniel/llm_notebooks/train_data_llama_factory_George_MacDonald.json'\n",
    "\n",
    "# Call the function to convert the file\n",
    "convert_jsonl_to_json(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7426140e-5d9c-4687-adfa-5243a893ab70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
