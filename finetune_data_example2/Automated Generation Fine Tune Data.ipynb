{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae9d2e6-d92d-48f2-9c66-e8ca1b1cfaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from openai import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad17076-0081-4c77-aaab-f71d9a4e86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_file(file_path, output_filename, client):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if len(p.strip().split()) >= 10]\n",
    "\n",
    "    jsonl_data = []\n",
    "    skipped_paragraphs = []\n",
    "    total_retries = 0\n",
    "\n",
    "    for i, paragraph in enumerate(paragraphs, start=1):\n",
    "        retry_count = 0\n",
    "        failure_reason = None\n",
    "\n",
    "        while retry_count < 5:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF/Meta-Llama-3-8B-Instruct-Q8_0.gguf\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are an expert novelist. Paraphrase the given text in your own words, refining the prose and making it a bit richer. Don't write additional story or meaning, keep the original meaning and form. The response should contain only one paragraph. Keep a similar length in your output to the original, not more than 50% difference, and shouldn't be shorter than the original text.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": paragraph\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0.9,\n",
    "            )\n",
    "            response = completion.choices[0].message.content.strip()\n",
    "\n",
    "            if \"###\" in response:\n",
    "                failure_reason = \"Response contains '###'\"\n",
    "            elif \"Paraphrased Text\" in response:\n",
    "                failure_reason = \"Response contains 'Paraphrased Text'\"\n",
    "            elif \"Alternate Refinement\" in response:\n",
    "                failure_reason = \"Response contains 'Alternate Refinement'\"\n",
    "            elif \"Extended Alternate Refinement\" in response:\n",
    "                failure_reason = \"Response contains 'Extended Alternate Refinement'\"\n",
    "            elif \"[Note:\" in response:\n",
    "                failure_reason = \"Response contains '[Note:'\"\n",
    "            elif \"### Question:\" in response:\n",
    "                failure_reason = \"Response contains '### Question:'\"\n",
    "            elif len(response.split('\\n\\n')) > 1:\n",
    "                failure_reason = \"Response contains multiple paragraphs\"\n",
    "            elif len(response.split()) < int(0.8 * len(paragraph.split())):\n",
    "                failure_reason = \"Response is less than 80% the size of the input\"\n",
    "            elif len(response.split()) > int(2 * len(paragraph.split())):\n",
    "                failure_reason = \"Response is more than 2 times the length of the input\"\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            retry_count += 1\n",
    "            total_retries += 1\n",
    "            print(f\"\\n- Retrying for paragraph {i}: {paragraph} \\n - Reason: {failure_reason} \\n - Response: {response}\")\n",
    "\n",
    "        if retry_count == 5:\n",
    "            print(f\"\\n Skipping paragraph {i} after 5 retries.\")\n",
    "            skipped_paragraphs.append((i, failure_reason))\n",
    "            continue\n",
    "\n",
    "        word_count = len(paragraph.split())\n",
    "        print(f\"\\n---> Paragraph {i} ({word_count} words):\")\n",
    "        print(f\"\\nInput: {paragraph}\")\n",
    "        print(f\"\\nOutput: {response}\")\n",
    "        print()\n",
    "\n",
    "        result = {\n",
    "            \"text\": f\"<human>: Rephrase the following text in the style of George MacDonald: {response}\\n<bot>: {paragraph}\",\n",
    "            \"metadata\": {\"source\": \"gutenberg\"}\n",
    "        }\n",
    "        jsonl_data.append(json.dumps(result, ensure_ascii=False))\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as output_file:\n",
    "        output_file.write('\\n'.join(jsonl_data))\n",
    "\n",
    "    total_paragraphs = len(paragraphs)\n",
    "    written_paragraphs = len(jsonl_data)\n",
    "    skipped_paragraphs_count = len(skipped_paragraphs)\n",
    "\n",
    "    print(\"Summary:\")\n",
    "    print(f\"Total paragraphs: {total_paragraphs}\")\n",
    "    print(f\"Written paragraphs: {written_paragraphs}\")\n",
    "    print(f\"Skipped paragraphs: {skipped_paragraphs_count}\")\n",
    "    print(f\"Total retries: {total_retries}\")\n",
    "    print(\"Skipped paragraph details:\")\n",
    "    for paragraph_number, reason in skipped_paragraphs:\n",
    "        print(f\"Paragraph {paragraph_number}: {reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fd515c-ef3b-47fb-a539-d47f5961de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'G:\\\\texts\\\\sample1_B.txt'\n",
    "output_file_path = 'G:\\\\texts\\\\train_data_book1_Drusniel_Meta-Llama-3-8B-Instruct-Q8_0.jsonl'\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "process_text_file(file_path, output_file_path, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eec32b-c442-4e1f-b3e8-009b7786be2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
